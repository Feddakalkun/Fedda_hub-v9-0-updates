import { NextRequest, NextResponse } from 'next/server';
import { falClient } from '@/lib/generators/fal-client';
import { comfyuiClient } from '@/lib/generators/comfyui-client';
import fs from 'fs/promises';
import path from 'path';

/**
 * Hybrid Pipeline: Fal.ai ‚Üí ComfyUI ‚Üí Refinement
 * 
 * Step 1: Generate base character with Fal.ai FLUX Pro (fast, ultra-realistic)
 * Step 2: Download the image
 * Step 3: Upload to ComfyUI and refine with LoRAs/Img2Img
 * Step 4: Return the final refined image
 */
export async function POST(request: NextRequest) {
    try {
        const body = await request.json();
        const {
            prompt,
            aspectRatio = '9:16',
            useComfyRefinement = true,
            comfyWorkflow,
            loras = [],
        } = body;

        // Step 1: Generate base character with Fal.ai
        console.log('üé® Generating base character with Fal.ai FLUX Pro...');
        const falResult = await falClient.generateCharacter({
            prompt,
            aspectRatio,
            numImages: 1,
        });

        if (!falResult.images || falResult.images.length === 0) {
            return NextResponse.json(
                { success: false, error: 'No images generated by Fal.ai' },
                { status: 500 }
            );
        }

        const baseImageUrl = falResult.images[0].url;
        console.log('‚úÖ Base character generated:', baseImageUrl);

        // If ComfyUI refinement is disabled, return the Fal.ai result
        if (!useComfyRefinement) {
            return NextResponse.json({
                success: true,
                source: 'fal',
                imageUrl: baseImageUrl,
                metadata: {
                    seed: falResult.seed,
                    prompt: falResult.prompt,
                },
            });
        }

        // Step 2: Download the image
        console.log('üì• Downloading image from Fal.ai...');
        const imageBuffer = await falClient.downloadImage(baseImageUrl);

        // Step 3: Upload to ComfyUI
        console.log('üì§ Uploading to ComfyUI...');
        const uploadResult = await comfyuiClient.uploadImage({
            image: imageBuffer,
            filename: `fal_base_${Date.now()}.png`,
            subfolder: 'fal_imports',
            overwrite: true,
        });

        // Step 4: Refine with ComfyUI (Img2Img with LoRAs)
        console.log('üîß Refining with ComfyUI...');

        // Load the workflow
        const workflowPath = path.join(process.cwd(), 'public/comfyui/workflows/Z-IMAGE-new.json');
        const workflowData = await fs.readFile(workflowPath, 'utf-8');
        const workflow = JSON.parse(workflowData);

        // Inject the uploaded image as source
        workflow['901'] = {
            inputs: {
                image: uploadResult.name,
                upload: 'image'
            },
            class_type: 'LoadImage',
        };
        workflow['902'] = {
            inputs: {
                pixels: ['901', 0],
                vae: ['17', 0]
            },
            class_type: 'VAEEncode',
        };

        // Set KSampler to use the loaded image
        if (workflow['3']) {
            workflow['3'].inputs.latent_image = ['902', 0];
            workflow['3'].inputs.denoise = 0.4; // Light refinement
        }

        // Apply LoRAs if provided
        if (loras.length > 0 && workflow['126']) {
            loras.forEach((lora: any, index: number) => {
                const key = `lora_${index + 1}`;
                workflow['126'].inputs[key] = {
                    on: true,
                    lora: lora.name,
                    strength: lora.strength || 1.0,
                    strength_clip: lora.strength || 1.0,
                };
            });
        }

        // Queue the workflow
        const queueResult = await comfyuiClient.queueWorkflow({ workflow });

        // Wait for completion (simplified - in production use WebSocket)
        await new Promise(resolve => setTimeout(resolve, 15000));

        // Get the result
        const historyResult = await comfyuiClient.getPromptStatus(queueResult.prompt_id);

        console.log('‚úÖ Hybrid pipeline complete!');

        return NextResponse.json({
            success: true,
            source: 'hybrid',
            promptId: queueResult.prompt_id,
            baseImageUrl,
            metadata: {
                falSeed: falResult.seed,
                comfyPromptId: queueResult.prompt_id,
            },
        });

    } catch (error: any) {
        console.error('‚ùå Hybrid pipeline error:', error);
        return NextResponse.json(
            {
                success: false,
                error: error.message || 'Failed to generate image',
                stack: error.stack,
            },
            { status: 500 }
        );
    }
}
